"""
RetailNova - Master Pipeline Orchestrator
==========================================
Simulates Azure Data Factory Master Pipeline with child pipelines.

Pattern: Master â†’ Child Pipelines with:
  - Parameterisation
  - Retry with exponential backoff
  - Conditional branching (skip gold if silver fails)
  - Alert simulation (email/teams notification)
  - SLA monitoring
  - Metadata-driven execution

This is the single entry point to run the full ETL stack.
"""

import sys
import time
import argparse
from datetime import datetime, timezone
from typing import List, Optional, Dict, Any, Callable
from enum import Enum

sys.path.insert(0, "/opt/bitnami/spark")

from pipelines.config            import pipeline_config, BRONZE_TABLES
from pipelines.logger            import pipeline_run, log_error, log_metric, generate_run_id
from pipelines.spark_session     import build_spark_session, stop_session
from pipelines.bronze_ingestion  import run_bronze_ingestion
from pipelines.silver_transformation import run_silver_transformation
from pipelines.gold_pipeline     import run_gold_pipeline
from quality_framework.dq_engine import run_quality_checks


# â”€â”€â”€ PIPELINE STATUS ENUM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class PipelineStatus(str, Enum):
    PENDING   = "PENDING"
    RUNNING   = "RUNNING"
    SUCCESS   = "SUCCESS"
    FAILED    = "FAILED"
    SKIPPED   = "SKIPPED"
    RETRYING  = "RETRYING"


# â”€â”€â”€ ALERT SIMULATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def send_alert(
    subject: str,
    message: str,
    severity: str = "WARNING",
    recipients: List[str] = None,
) -> None:
    """
    Simulate Azure Monitor alert / Teams webhook notification.

    In production: this calls Azure Logic Apps â†’ sends email/Teams message.
    For local dev: just prints the alert with formatting.
    """
    border = "=" * 65
    print(f"\n{'ğŸ”´' if severity == 'CRITICAL' else 'âš ï¸ '} ALERT [{severity}]")
    print(border)
    print(f"  Subject  : {subject}")
    print(f"  Message  : {message}")
    print(f"  Time     : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"  Recipients: {recipients or [pipeline_config.alert_email]}")
    print(border + "\n")


def check_sla(start_time: datetime, pipeline_name: str) -> None:
    """Warn if pipeline is approaching SLA threshold."""
    elapsed_hours = (datetime.now(timezone.utc) - start_time).total_seconds() / 3600
    if elapsed_hours > pipeline_config.sla_hours:
        send_alert(
            subject=f"SLA BREACH: {pipeline_name}",
            message=(
                f"Pipeline '{pipeline_name}' has been running for "
                f"{elapsed_hours:.1f}h, exceeding SLA of {pipeline_config.sla_hours}h."
            ),
            severity="CRITICAL",
        )


# â”€â”€â”€ RETRY WRAPPER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_with_retry(
    fn: Callable,
    pipeline_name: str,
    max_retries: int = None,
    retry_delay: int = None,
    **kwargs,
) -> bool:
    """
    Execute a pipeline function with exponential backoff retry.
    Returns True on success, False if all retries exhausted.

    In Azure Data Factory: this maps to Activity Retry Policy settings.
    """
    max_retries  = max_retries  or pipeline_config.max_retries
    retry_delay  = retry_delay  or pipeline_config.retry_delay_secs
    attempt      = 0

    while attempt <= max_retries:
        try:
            if attempt > 0:
                wait = retry_delay * (2 ** (attempt - 1))   # exponential backoff
                print(f"  [RETRY] {pipeline_name} attempt {attempt}/{max_retries} "
                      f"in {wait}s...")
                time.sleep(wait)

            fn(**kwargs)
            return True

        except Exception as exc:
            attempt += 1
            print(f"  [ERROR] {pipeline_name} attempt {attempt} failed: {exc}")

            if attempt > max_retries:
                send_alert(
                    subject=f"PIPELINE FAILURE: {pipeline_name}",
                    message=f"All {max_retries} retries exhausted. Error: {exc}",
                    severity="CRITICAL",
                )
                return False

    return False


# â”€â”€â”€ CHILD PIPELINE: BRONZE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def child_pipeline_bronze(spark, tables: List[str] = None) -> PipelineStatus:
    print(f"\n  â•”â•â• CHILD PIPELINE: Bronze Ingestion â•â•â•—")
    success = run_with_retry(
        run_bronze_ingestion,
        "bronze_ingestion",
        spark=spark,
        tables=tables,
    )
    status = PipelineStatus.SUCCESS if success else PipelineStatus.FAILED
    print(f"  â•šâ•â• Bronze: {status.value} â•â•â•")
    return status


# â”€â”€â”€ CHILD PIPELINE: SILVER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def child_pipeline_silver(spark) -> PipelineStatus:
    print(f"\n  â•”â•â• CHILD PIPELINE: Silver Transformation â•â•â•—")
    success = run_with_retry(
        run_silver_transformation,
        "silver_transformation",
        spark=spark,
    )
    status = PipelineStatus.SUCCESS if success else PipelineStatus.FAILED
    print(f"  â•šâ•â• Silver: {status.value} â•â•â•")
    return status


# â”€â”€â”€ CHILD PIPELINE: QUALITY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def child_pipeline_quality(spark, layer: str = "silver") -> PipelineStatus:
    print(f"\n  â•”â•â• CHILD PIPELINE: Data Quality ({layer}) â•â•â•—")
    try:
        results = run_quality_checks(
            spark, layer=layer,
            pipeline_name=f"dq_{layer}",
            raise_on_critical=False,  # Orchestrator handles this
        )
        # Count failures
        critical_fails = [r for r in results if r.status == "FAIL" and r.severity == "CRITICAL"]
        warnings       = [r for r in results if r.status == "WARNING"]

        if warnings:
            send_alert(
                subject=f"Data Quality Warnings ({layer})",
                message=f"{len(warnings)} quality warnings found. Review data_quality_log.",
                severity="WARNING",
            )

        if critical_fails:
            send_alert(
                subject=f"Data Quality CRITICAL FAILURES ({layer})",
                message=(
                    f"{len(critical_fails)} critical rules failed: "
                    f"{[r.rule_name for r in critical_fails]}"
                ),
                severity="CRITICAL",
            )
            print(f"  â•šâ•â• Quality ({layer}): FAILED â•â•â•")
            return PipelineStatus.FAILED

        print(f"  â•šâ•â• Quality ({layer}): SUCCESS â•â•â•")
        return PipelineStatus.SUCCESS

    except Exception as e:
        print(f"  [Quality ERROR] {e}")
        print(f"  â•šâ•â• Quality ({layer}): FAILED â•â•â•")
        return PipelineStatus.FAILED


# â”€â”€â”€ CHILD PIPELINE: GOLD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def child_pipeline_gold(spark) -> PipelineStatus:
    print(f"\n  â•”â•â• CHILD PIPELINE: Gold Layer â•â•â•—")
    success = run_with_retry(
        run_gold_pipeline,
        "gold_pipeline",
        spark=spark,
    )
    status = PipelineStatus.SUCCESS if success else PipelineStatus.FAILED
    print(f"  â•šâ•â• Gold: {status.value} â•â•â•")
    return status


# â”€â”€â”€ MASTER PIPELINE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_master_pipeline(
    run_bronze: bool = True,
    run_silver: bool = True,
    run_gold:   bool = True,
    run_quality: bool = True,
    tables: List[str] = None,
    fail_fast: bool = False,
) -> Dict[str, PipelineStatus]:
    """
    Master pipeline that orchestrates all child pipelines.

    Branching logic:
      - Bronze fail â†’ Silver skipped (no source data)
      - Silver fail â†’ Gold skipped + Quality WARN (no clean data)
      - Quality critical fail â†’ Alert but Gold continues (data delivered)
      - Gold fail â†’ Alert, upstream data still available in Silver

    Parameterisation:
      - tables: run only specific source tables
      - fail_fast: stop entire pipeline on first failure
    """
    master_start = datetime.now(timezone.utc)
    master_run_id = generate_run_id("master_pipeline")

    print(f"\n{'â•”' + 'â•'*63 + 'â•—'}")
    print(f"â•‘  RETAILNOVA MASTER PIPELINE                                  â•‘")
    print(f"â•‘  run_id : {master_run_id:<52} â•‘")
    print(f"â•‘  start  : {master_start.strftime('%Y-%m-%d %H:%M:%S UTC'):<52} â•‘")
    print(f"â•š{'â•'*63}â•")

    spark   = build_spark_session("RetailNova-Master-Pipeline")
    results = {}

    try:
        # â”€â”€ STAGE 1: Bronze Ingestion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if run_bronze:
            results["bronze"] = child_pipeline_bronze(spark, tables)
            check_sla(master_start, "bronze_ingestion")

            if results["bronze"] == PipelineStatus.FAILED:
                send_alert("Bronze Ingestion Failed",
                           "Cannot proceed to Silver without source data.",
                           "CRITICAL")
                if fail_fast:
                    return results
                # Skip Silver and Gold â€” no source data
                results["silver"]  = PipelineStatus.SKIPPED
                results["quality"] = PipelineStatus.SKIPPED
                results["gold"]    = PipelineStatus.SKIPPED
                return results

        # â”€â”€ STAGE 2: Silver Transformation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if run_silver:
            results["silver"] = child_pipeline_silver(spark)
            check_sla(master_start, "silver_transformation")

            if results["silver"] == PipelineStatus.FAILED:
                send_alert("Silver Transformation Failed",
                           "Gold pipeline will be skipped.",
                           "CRITICAL")
                if fail_fast:
                    return results

        # â”€â”€ STAGE 3: Data Quality (Silver) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if run_quality and results.get("silver") != PipelineStatus.SKIPPED:
            results["quality_silver"] = child_pipeline_quality(spark, "silver")

        # â”€â”€ STAGE 4: Gold Layer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if run_gold and results.get("silver") != PipelineStatus.FAILED:
            results["gold"] = child_pipeline_gold(spark)
            check_sla(master_start, "gold_pipeline")

            if results["gold"] == PipelineStatus.SUCCESS and run_quality:
                results["quality_gold"] = child_pipeline_quality(spark, "gold")
        else:
            if results.get("silver") == PipelineStatus.FAILED:
                results["gold"] = PipelineStatus.SKIPPED
                print("  [SKIP] Gold pipeline skipped due to Silver failure.")

        # â”€â”€ SUMMARY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        elapsed = (datetime.now(timezone.utc) - master_start).total_seconds()
        log_metric(master_run_id, "master_pipeline", "total_duration_seconds",
                   elapsed, "seconds")

        print(f"\n{'â•”' + 'â•'*63 + 'â•—'}")
        print(f"â•‘  MASTER PIPELINE SUMMARY                                    â•‘")
        print(f"â• {'â•'*63}â•£")
        for stage, status in results.items():
            icon = "âœ“" if status == PipelineStatus.SUCCESS else (
                   "â—‹" if status == PipelineStatus.SKIPPED else "âœ—")
            print(f"â•‘  {icon} {stage:<20} : {status.value:<38} â•‘")
        print(f"â• {'â•'*63}â•£")
        print(f"â•‘  Duration: {elapsed:.1f}s{' ':>50}â•‘")
        print(f"â•š{'â•'*63}â•\n")

        # Final SLA check
        check_sla(master_start, "master_pipeline")

        return results

    except Exception as e:
        send_alert(
            "MASTER PIPELINE FATAL ERROR",
            str(e),
            "CRITICAL",
        )
        log_error(master_run_id, "master_pipeline", "FatalError", str(e), "CRITICAL")
        raise

    finally:
        stop_session(spark)


# â”€â”€â”€ CLI ENTRY POINT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def parse_args():
    parser = argparse.ArgumentParser(
        description="RetailNova Enterprise Data Platform - Master Pipeline"
    )
    parser.add_argument(
        "--layer", choices=["all", "bronze", "silver", "gold", "quality"],
        default="all", help="Which layer(s) to run"
    )
    parser.add_argument(
        "--tables", nargs="+", default=None,
        help="Specific source tables to ingest (bronze only)"
    )
    parser.add_argument(
        "--fail-fast", action="store_true",
        help="Stop pipeline on first failure"
    )
    parser.add_argument(
        "--skip-quality", action="store_true",
        help="Skip data quality checks"
    )
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()

    run_master_pipeline(
        run_bronze  = args.layer in ("all", "bronze"),
        run_silver  = args.layer in ("all", "silver"),
        run_gold    = args.layer in ("all", "gold"),
        run_quality = not args.skip_quality,
        tables      = args.tables,
        fail_fast   = args.fail_fast,
    )
